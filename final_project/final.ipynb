{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence id</th>\n",
       "      <th>token id</th>\n",
       "      <th>token</th>\n",
       "      <th>BIO NER tag</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>would</td>\n",
       "      <td>O</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>n't</td>\n",
       "      <td>O</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>be</td>\n",
       "      <td>O</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>caught</td>\n",
       "      <td>O</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>dead</td>\n",
       "      <td>O</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>watching</td>\n",
       "      <td>O</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NFL</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>if</td>\n",
       "      <td>O</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>it</td>\n",
       "      <td>O</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>were</td>\n",
       "      <td>O</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>n't</td>\n",
       "      <td>O</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>Swift</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Chris</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>O'Donnell</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>stated</td>\n",
       "      <td>O</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence id  token id      token BIO NER tag  POS\n",
       "0             0         0          I           O  PRP\n",
       "1             0         1      would           O   MD\n",
       "2             0         2        n't           O   RB\n",
       "3             0         3         be           O   VB\n",
       "4             0         4     caught           O   NN\n",
       "5             0         5       dead           O   JJ\n",
       "6             0         6   watching           O  VBG\n",
       "7             0         7        the           O   DT\n",
       "8             0         8        NFL       B-ORG   NN\n",
       "9             0         9         if           O   IN\n",
       "10            0        10         it           O  PRP\n",
       "11            0        11       were           O  VBD\n",
       "12            0        12        n't           O   RB\n",
       "13            0        13        for           O   IN\n",
       "14            0        14     Taylor       B-PER   NN\n",
       "15            0        15      Swift       I-PER   NN\n",
       "16            0        16          .           O    .\n",
       "17            1         0      Chris       B-PER   NN\n",
       "18            1         1  O'Donnell       I-PER   NN\n",
       "19            1         2     stated           O  VBN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ner_test = pd.read_csv('data/ner-test.tsv', delimiter='\\t')\n",
    "\n",
    "# adding POS tags\n",
    "def pos_tagging(token):\n",
    "    return nltk.pos_tag([token])[0][1]\n",
    "\n",
    "df_ner_test['POS'] = df_ner_test['token'].apply(pos_tagging)\n",
    "df_ner_test.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Added the NLTK pos_tags to the test set because they are a useful feature for NERC.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = []\n",
    "test_gold_labels = []\n",
    "\n",
    "test_words = df_ner_test.iterrows()\n",
    "for i, row in test_words:\n",
    "    token: str = row['token']\n",
    "    \n",
    "    a_dict = {\n",
    "        'word': token,                # the word itself\n",
    "        'pos': row['POS'],                   # the part of speech\n",
    "        'word[-3:]': token[-3:],      # the last three characters of the word\n",
    "        'word[-2:]': token[-2:],      # the last two characters of the word\n",
    "        'upper': token[0].isupper(),  # whether the first letter is uppercase\n",
    "        'title': token.istitle(),      # whether the word is titlecased \n",
    "        'prev-word': None\n",
    "                                 \n",
    "        # 'upper' and 'lower' will be slightly different because\n",
    "        # of words like 'EU'\n",
    "    }\n",
    "    \n",
    "    #If we have a previous word, add it to the features list to improve NERC\n",
    "    if i > 0:\n",
    "        # only get previous word if they're part of the same sentence\n",
    "        prev_row = df_ner_test.iloc[i - 1]\n",
    "        \n",
    "        if prev_row['sentence id'] == row['sentence id']:\n",
    "            a_dict['prev-word'] = prev_row['token']\n",
    "\n",
    "    test_features.append(a_dict)\n",
    "    test_gold_labels.append(row['BIO NER tag'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "### Adapt the path to point to the CONLL2003 folder on your local machine\n",
    "train = ConllCorpusReader('./data/CONLL2003', 'train.txt', ['words', 'pos', 'ignore', 'chunk'])\n",
    "training_features = []\n",
    "training_gold_labels = []\n",
    "\n",
    "train_words = list(train.iob_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'O': 169578, 'B-LOC': 7140, 'B-PER': 6600, 'B-ORG': 6321, 'I-PER': 4528, 'I-ORG': 3704, 'B-MISC': 3438, 'I-LOC': 1157, 'I-MISC': 1155})\n",
      "Counter({'O': 160, 'I-WORK_OF_ART': 9, 'B-PER': 6, 'I-ORG': 6, 'B-WORK_OF_ART': 4, 'B-ORG': 3, 'I-PER': 3, 'B-DATE': 1, 'I-DATE': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(train_words[i][2] for i in range(len(train_words))))\n",
    "print(Counter(df_ner_test['BIO NER tag']))\n",
    "\n",
    "for i, (token, pos, ne_label) in enumerate(train_words):\n",
    "   if token == '' or token == 'DOCSTART':\n",
    "      continue\n",
    "   \n",
    "   a_dict = {\n",
    "      'word': token,                # the word itself\n",
    "      'pos': pos,                   # the part of speech\n",
    "      'word[-3:]': token[-3:],      # the last three characters of the word\n",
    "      'word[-2:]': token[-2:],      # the last two characters of the word\n",
    "      'upper': token[0].isupper(),  # whether the first letter is uppercase\n",
    "      'title': token.istitle(),     # whether the word is titlecased \n",
    "      'prev-word': None,       # the previous word (None if it's the first word in the dataset)\n",
    "   }\n",
    "   \n",
    "   # If the sentence is not ending\n",
    "   if i > 0:\n",
    "      prev_token = train_words[i - 1][0]\n",
    "      if prev_token != '.':\n",
    "         a_dict['prev-word'] = prev_token\n",
    "      \n",
    "\n",
    "   training_features.append(a_dict)\n",
    "   training_gold_labels.append(ne_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "path = \"C:\\\\Users\\\\Yari\\\\Downloads\\\\GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "word_embedding_model = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def get_train_vectors_labels() -> tuple[list, list]:\n",
    "    input_vectors = []\n",
    "    labels = []\n",
    "    \n",
    "    for token, _, ne_label in train_words:\n",
    "        if token =='' or token == 'DOCSTART':\n",
    "            continue\n",
    "        \n",
    "        if token in word_embedding_model:\n",
    "            vector = word_embedding_model[token]\n",
    "        else:\n",
    "            vector = [0]*300\n",
    "            \n",
    "        input_vectors.append(vector)\n",
    "        labels.append(ne_label)\n",
    "        \n",
    "    return (input_vectors, labels)\n",
    "\n",
    "def get_vectors_labels(data: pd.DataFrame) -> tuple[list, list]:\n",
    "    input_vectors = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        token = row['token']\n",
    "        ne_label = row['BIO NER tag']\n",
    "\n",
    "        if token in word_embedding_model:\n",
    "            vector = word_embedding_model[token]\n",
    "        else:\n",
    "            vector = [0] * 300\n",
    "        input_vectors.append(vector)\n",
    "        labels.append(ne_label)\n",
    "            \n",
    "    return (input_vectors, labels)\n",
    "\n",
    "input_vectors, labels = get_train_vectors_labels()\n",
    "test_input_vectors, test_labels = get_vectors_labels(df_ner_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "       B-DATE       0.00      0.00      0.00         1\n",
      "       B-MISC       0.00      0.00      0.00         0\n",
      "        B-ORG       0.40      0.67      0.50         3\n",
      "        B-PER       0.67      0.67      0.67         6\n",
      "B-WORK_OF_ART       0.00      0.00      0.00         4\n",
      "       I-DATE       0.00      0.00      0.00         1\n",
      "        I-LOC       0.00      0.00      0.00         0\n",
      "        I-ORG       0.00      0.00      0.00         6\n",
      "        I-PER       0.50      0.33      0.40         3\n",
      "I-WORK_OF_ART       0.00      0.00      0.00         9\n",
      "            O       0.91      1.00      0.96       160\n",
      "\n",
      "     accuracy                           0.87       193\n",
      "    macro avg       0.23      0.24      0.23       193\n",
      " weighted avg       0.79      0.87      0.83       193\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_clf.fit(input_vectors, labels)\n",
    "predicted_labels = lin_clf.predict(test_input_vectors)\n",
    "\n",
    "report = classification_report(test_labels, predicted_labels)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
