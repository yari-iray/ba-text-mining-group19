{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kelvin Brachthuizen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sn \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "own_data = pd.read_csv('data/own_dataset.tsv', sep='\\t')\n",
    "test_data = pd.read_csv('data/sentiment-topic-test.tsv', sep='\\t')\n",
    "\n",
    "#remove sentiment column and sentence id column\n",
    "own_data = own_data.drop(columns=['sentiment'])\n",
    "own_data = own_data.drop(columns=['sentence id'])\n",
    "test_data = test_data.drop(columns=['sentiment'])\n",
    "test_data = test_data.drop(columns=['sentence id'])\n",
    "\n",
    "#change each value in topic to an integer\n",
    "own_data['topic'] = own_data['topic'].astype('category')\n",
    "own_data['topic'] = own_data['topic'].cat.codes\n",
    "test_data['topic'] = test_data['topic'].astype('category')\n",
    "test_data['topic'] = test_data['topic'].cat.codes\n",
    "\n",
    "#change topic header to labels\n",
    "own_data = own_data.rename(columns={\"topic\": \"labels\"})\n",
    "test_data = test_data.rename(columns={\"topic\": \"labels\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([own_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "train, test = train_test_split(own_data, test_size=10, shuffle=False)\n",
    "train, dev = train_test_split(train, test_size=0.3, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration # https://simpletransformers.ai/docs/usage/#configuring-a-simple-transformers-model \n",
    "model_args = ClassificationArgs()\n",
    "\n",
    "model_args.overwrite_output_dir=True # overwrite existing saved models in the same directory\n",
    "model_args.evaluate_during_training=True # to perform evaluation while training the model\n",
    "# (eval data should be passed to the training method)\n",
    "\n",
    "model_args.num_train_epochs=15 # number of epochs\n",
    "model_args.train_batch_size=64 # batch size\n",
    "model_args.learning_rate=4e-5 # learning rate\n",
    "model_args.max_seq_length=256 # maximum sequence length\n",
    "# Note! Increasing max_seq_len may provide better performance, but training time will increase. \n",
    "# For educational purposes, we set max_seq_len to 256.\n",
    "\n",
    "# Early stopping to combat overfitting: https://simpletransformers.ai/docs/tips-and-tricks/#using-early-stopping\n",
    "model_args.use_early_stopping=True\n",
    "model_args.early_stopping_delta=0.01 # \"The improvement over best_eval_loss necessary to count as a better checkpoint\"\n",
    "model_args.early_stopping_metric='eval_loss'\n",
    "model_args.early_stopping_metric_minimize=True\n",
    "model_args.early_stopping_patience=2\n",
    "model_args.evaluate_during_training_steps=32 # how often you want to run validation in terms of training steps (or batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1it [00:08,  8.06s/it]\n",
      "Epochs 1/15. Running Loss:    1.1860: 100%|██████████| 1/1 [14:10<00:00, 850.50s/it]\n",
      "1it [00:07,  7.89s/it]\n",
      "Epochs 2/15. Running Loss:    1.1748: 100%|██████████| 1/1 [01:13<00:00, 73.62s/it]\n",
      "1it [00:07,  7.48s/it]\n",
      "Epochs 3/15. Running Loss:    1.0593: 100%|██████████| 1/1 [00:37<00:00, 37.13s/it]\n",
      "1it [00:07,  7.20s/it]\n",
      "Epochs 4/15. Running Loss:    1.0322: 100%|██████████| 1/1 [00:37<00:00, 37.36s/it]\n",
      "1it [00:07,  7.23s/it]\n",
      "Epochs 5/15. Running Loss:    0.9660: 100%|██████████| 1/1 [00:37<00:00, 37.26s/it]\n",
      "1it [00:07,  7.21s/it]\n",
      "Epochs 6/15. Running Loss:    0.9049: 100%|██████████| 1/1 [00:36<00:00, 36.49s/it]\n",
      "1it [00:07,  7.58s/it]\n",
      "Epochs 7/15. Running Loss:    0.8431: 100%|██████████| 1/1 [00:37<00:00, 37.58s/it]\n",
      "1it [00:09,  9.04s/it]\n",
      "Epochs 8/15. Running Loss:    0.7874: 100%|██████████| 1/1 [00:38<00:00, 38.20s/it]\n",
      "1it [00:10, 10.60s/it]\n",
      "Epochs 9/15. Running Loss:    0.7579: 100%|██████████| 1/1 [00:37<00:00, 37.08s/it]\n",
      "1it [00:07,  7.37s/it]\n",
      "Epochs 10/15. Running Loss:    0.6900: 100%|██████████| 1/1 [00:35<00:00, 35.91s/it]\n",
      "1it [00:07,  7.20s/it]\n",
      "Epochs 11/15. Running Loss:    0.6391: 100%|██████████| 1/1 [00:36<00:00, 36.40s/it]\n",
      "1it [00:07,  7.26s/it]\n",
      "Epochs 12/15. Running Loss:    0.6190: 100%|██████████| 1/1 [00:37<00:00, 37.06s/it]\n",
      "1it [00:07,  7.17s/it]\n",
      "Epochs 13/15. Running Loss:    0.5545: 100%|██████████| 1/1 [00:36<00:00, 36.79s/it]\n",
      "1it [00:07,  7.18s/it]\n",
      "Epochs 14/15. Running Loss:    0.5161: 100%|██████████| 1/1 [00:37<00:00, 37.94s/it]\n",
      "1it [00:07,  7.23s/it]\n",
      "Epochs 15/15. Running Loss:    0.5084: 100%|██████████| 1/1 [00:37<00:00, 37.27s/it]\n",
      "1it [00:14, 14.19s/it]\n",
      "Epoch 15 of 15: 100%|██████████| 15/15 [32:09<00:00, 128.63s/it]\n"
     ]
    }
   ],
   "source": [
    "bert_model = ClassificationModel('bert', 'bert-base-cased', num_labels=3, args=model_args, use_cuda=True) # CUDA is enabled\n",
    "_, history = bert_model.train_model(train, eval_df=dev, multi_label=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.45s/it]\n",
      "Running Evaluation: 100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n",
      "1it [00:07,  7.15s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model: ClassificationModel, dev: pd.DataFrame, test:pd.DataFrame):\n",
    "    result, outputs, wrong_pred = model.eval_model(dev)\n",
    "    \n",
    "    predicted, probabilities = model.predict(test.text.to_list())\n",
    "    test['predicted'] = predicted\n",
    "    \n",
    "    print(classification_report(test['labels'], test['predicted']))\n",
    "\n",
    "evaluate_model(bert_model, dev, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
