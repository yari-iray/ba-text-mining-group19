{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab6.2: Topic modeling using gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate how LDA models can be built and applied using the *gensim* package.\n",
    "\n",
    "Credits:\n",
    "\n",
    "This notebook is an adaptation of a blog from Susan Li's:\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set we’ll use is a list of over one million news headlines published over a period of 15 years and can be downloaded from:\n",
    "\n",
    "https://www.kaggle.com/therohk/million-headlines/data\n",
    "\n",
    "We read the CSV file using the pandas framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#### Adapt the path below to point to your local copy of the data set\n",
    "data = pd.read_csv('./data/abcnews-date-text.csv', on_bad_lines='warn');\n",
    "data_text = data[['headline_text']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1244184\n",
      "                                       headline_text  index\n",
      "0  aba decides against community broadcasting lic...      0\n",
      "1     act fire witnesses must be aware of defamation      1\n",
      "2     a g calls for infrastructure protection summit      2\n",
      "3           air nz staff in aust strike for pay rise      3\n",
      "4      air nz strike to affect australian travellers      4\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print(documents[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the *gensim* package to build our LDA models from the data.\n",
    "Before building the model, we are going to preprocess the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "We will perform the following steps:\n",
    "\n",
    "* Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
    "* Words that have fewer than 3 characters are removed.\n",
    "* All stopwords are removed.\n",
    "* Words are lemmatized — words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
    "* Words are stemmed — words are reduced to their root form.\n",
    "\n",
    "In order to apply these processing steps, we first load the gensim and nltk libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/axelehrnrooth/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return lemmatizer.lemmatize(text)\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "           # result.append(token)\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['ratepayers', 'group', 'wants', 'compulsory', 'local', 'govt', 'voting']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['ratepayer', 'group', 'want', 'compulsory', 'local', 'govt', 'voting']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the preprocessing to all the headlines and print the first 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [decides, community, broadcasting, licence]\n",
       "1                         [witness, aware, defamation]\n",
       "2           [call, infrastructure, protection, summit]\n",
       "3                          [staff, aust, strike, rise]\n",
       "4              [strike, affect, australian, traveller]\n",
       "5               [ambitious, olsson, win, triple, jump]\n",
       "6          [antic, delighted, record, breaking, barca]\n",
       "7    [aussie, qualifier, stosur, waste, memphis, ma...\n",
       "8             [aust, address, security, council, iraq]\n",
       "9                       [australia, locked, timetable]\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['headline_text'].map(preprocess)\n",
    "### print the first 10 results\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words on the Data set\n",
    "Create a dictionary from ‘processed_docs’ containing the number of times a word appears in the training set.\n",
    "We are going to use the *Dictionary* function to derive a dictionary with counts from the headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 broadcasting\n",
      "1 community\n",
      "2 decides\n",
      "3 licence\n",
      "4 aware\n",
      "5 defamation\n",
      "6 witness\n",
      "7 call\n",
      "8 infrastructure\n",
      "9 protection\n",
      "10 summit\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim filter_extremes\n",
    "Filter out tokens that appear in\n",
    "less than 15 documents (absolute number) or\n",
    "more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
    "after the above two steps, keep only the first 100000 most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim doc2bow\n",
    "For each document we create a dictionary reporting how many words and how many times those words appear. \n",
    "Gensim provides the *doc2bow* function to create a BoW vector representation for a document.\n",
    "Save this to ‘bow_corpus’, then check our selected document earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(164, 1), (241, 1), (615, 1), (891, 1), (4173, 1), (4174, 1), (4175, 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview Bag Of Words for our sample preprocessed document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 164 (\"govt\") appears 1 time.\n",
      "Word 241 (\"group\") appears 1 time.\n",
      "Word 615 (\"local\") appears 1 time.\n",
      "Word 891 (\"want\") appears 1 time.\n",
      "Word 4173 (\"compulsory\") appears 1 time.\n",
      "Word 4174 (\"ratepayer\") appears 1 time.\n",
      "Word 4175 (\"voting\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "Create tf-idf model object using models.TfidfModel on ‘bow_corpus’ and save it to ‘tfidf’, then apply transformation to the entire corpus and call it ‘corpus_tfidf’. Finally we preview TF-IDF scores for our first document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.6161125947380649),\n",
      " (1, 0.3308772069039591),\n",
      " (2, 0.5681053683635203),\n",
      " (3, 0.43379930266554434)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using Bag of Words\n",
    "Train our lda model using gensim.models.LdaMulticore and save it to ‘lda_model’. This takes a while.\n",
    "Look at the documentation of *gensim* for further details:\n",
    "\n",
    "https://radimrehurek.com/gensim/models/ldamulticore.html\n",
    "\n",
    "As parameters, we pass the corpus data as BoW (a list of lists of tuples), the prefixed number of topics, the actual words and the number of passes and workers used for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each topic, we will explore the words occuring in that topic and its relative weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.055*\"covid\" + 0.038*\"victoria\" + 0.037*\"coronavirus\" + 0.034*\"case\" + 0.023*\"child\" + 0.016*\"scott\" + 0.015*\"island\" + 0.012*\"border\" + 0.010*\"deal\" + 0.010*\"beach\"\n",
      "Topic: 1 \n",
      "Words: 0.024*\"restriction\" + 0.024*\"canberra\" + 0.023*\"life\" + 0.019*\"water\" + 0.016*\"police\" + 0.015*\"missing\" + 0.015*\"country\" + 0.015*\"concern\" + 0.014*\"claim\" + 0.013*\"farmer\"\n",
      "Topic: 2 \n",
      "Words: 0.040*\"sydney\" + 0.030*\"election\" + 0.017*\"lockdown\" + 0.012*\"andrew\" + 0.011*\"state\" + 0.011*\"president\" + 0.011*\"commission\" + 0.010*\"say\" + 0.010*\"biden\" + 0.009*\"australia\"\n",
      "Topic: 3 \n",
      "Words: 0.043*\"queensland\" + 0.026*\"south\" + 0.017*\"north\" + 0.016*\"victorian\" + 0.015*\"australia\" + 0.015*\"indigenous\" + 0.015*\"morrison\" + 0.013*\"west\" + 0.013*\"student\" + 0.013*\"school\"\n",
      "Topic: 4 \n",
      "Words: 0.036*\"police\" + 0.030*\"woman\" + 0.027*\"court\" + 0.024*\"death\" + 0.023*\"donald\" + 0.019*\"murder\" + 0.018*\"people\" + 0.016*\"year\" + 0.015*\"charged\" + 0.015*\"face\"\n",
      "Topic: 5 \n",
      "Words: 0.030*\"government\" + 0.020*\"health\" + 0.015*\"tasmania\" + 0.014*\"plan\" + 0.013*\"federal\" + 0.011*\"say\" + 0.011*\"care\" + 0.010*\"council\" + 0.010*\"call\" + 0.010*\"regional\"\n",
      "Topic: 6 \n",
      "Words: 0.021*\"crash\" + 0.017*\"house\" + 0.015*\"bushfire\" + 0.015*\"dy\" + 0.014*\"adelaide\" + 0.011*\"climate\" + 0.011*\"darwin\" + 0.009*\"home\" + 0.009*\"road\" + 0.009*\"week\"\n",
      "Topic: 7 \n",
      "Words: 0.035*\"coronavirus\" + 0.019*\"news\" + 0.018*\"china\" + 0.017*\"covid\" + 0.017*\"australia\" + 0.017*\"record\" + 0.016*\"market\" + 0.015*\"australian\" + 0.013*\"live\" + 0.011*\"coast\"\n",
      "Topic: 8 \n",
      "Words: 0.022*\"national\" + 0.017*\"change\" + 0.015*\"premier\" + 0.015*\"return\" + 0.014*\"tasmanian\" + 0.013*\"work\" + 0.012*\"rural\" + 0.011*\"show\" + 0.011*\"say\" + 0.011*\"risk\"\n",
      "Topic: 9 \n",
      "Words: 0.040*\"trump\" + 0.020*\"vaccine\" + 0.017*\"australia\" + 0.015*\"test\" + 0.014*\"open\" + 0.013*\"world\" + 0.013*\"final\" + 0.012*\"royal\" + 0.010*\"interview\" + 0.009*\"pandemic\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you distinguish different topics using the words in each topic and their corresponding weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.011*\"climate\" + 0.009*\"hill\" + 0.009*\"david\" + 0.007*\"grand\" + 0.006*\"america\" + 0.006*\"change\" + 0.005*\"australia\" + 0.005*\"murray\" + 0.005*\"capital\" + 0.005*\"sunday\"\n",
      "Topic: 1 Word: 0.017*\"coronavirus\" + 0.015*\"covid\" + 0.012*\"country\" + 0.009*\"market\" + 0.008*\"lockdown\" + 0.008*\"hour\" + 0.007*\"price\" + 0.006*\"australian\" + 0.006*\"business\" + 0.006*\"farm\"\n",
      "Topic: 2 Word: 0.011*\"australia\" + 0.010*\"scott\" + 0.009*\"world\" + 0.008*\"league\" + 0.007*\"update\" + 0.006*\"south\" + 0.006*\"korea\" + 0.006*\"coronavirus\" + 0.005*\"sentenced\" + 0.005*\"australian\"\n",
      "Topic: 3 Word: 0.013*\"government\" + 0.010*\"health\" + 0.008*\"federal\" + 0.007*\"budget\" + 0.006*\"election\" + 0.006*\"funding\" + 0.006*\"say\" + 0.005*\"mental\" + 0.005*\"labor\" + 0.005*\"school\"\n",
      "Topic: 4 Word: 0.011*\"speaks\" + 0.007*\"vaccine\" + 0.007*\"christmas\" + 0.007*\"history\" + 0.006*\"august\" + 0.006*\"october\" + 0.006*\"coronavirus\" + 0.006*\"george\" + 0.005*\"know\" + 0.005*\"quarantine\"\n",
      "Topic: 5 Word: 0.028*\"trump\" + 0.013*\"live\" + 0.011*\"crash\" + 0.007*\"dy\" + 0.007*\"dead\" + 0.006*\"extended\" + 0.006*\"killed\" + 0.006*\"alan\" + 0.005*\"house\" + 0.005*\"coronavirus\"\n",
      "Topic: 6 Word: 0.012*\"restriction\" + 0.011*\"border\" + 0.009*\"weather\" + 0.008*\"aged\" + 0.008*\"coronavirus\" + 0.008*\"care\" + 0.008*\"sport\" + 0.007*\"peter\" + 0.006*\"july\" + 0.006*\"james\"\n",
      "Topic: 7 Word: 0.020*\"news\" + 0.015*\"donald\" + 0.014*\"rural\" + 0.012*\"morrison\" + 0.009*\"friday\" + 0.009*\"wednesday\" + 0.008*\"national\" + 0.007*\"violence\" + 0.007*\"domestic\" + 0.007*\"outback\"\n",
      "Topic: 8 Word: 0.018*\"police\" + 0.013*\"murder\" + 0.012*\"charged\" + 0.011*\"court\" + 0.011*\"drum\" + 0.009*\"death\" + 0.009*\"charge\" + 0.008*\"woman\" + 0.008*\"guilty\" + 0.007*\"child\"\n",
      "Topic: 9 Word: 0.019*\"interview\" + 0.010*\"andrew\" + 0.009*\"story\" + 0.009*\"monday\" + 0.009*\"thursday\" + 0.007*\"daniel\" + 0.007*\"royal\" + 0.006*\"john\" + 0.006*\"footage\" + 0.005*\"abbott\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, can you distinguish different topics using the words in each topic and their corresponding weights? Do you observe any differences with the BoW version? Do these differences make sense given the information value weighing by the *tfidf* method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation by classifying sample document using LDA Bag of Words model\n",
    "We will check where our test document would be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratepayer', 'group', 'want', 'compulsory', 'local', 'govt', 'voting']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[4310]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document 4310 is already represented in the correct way. We can directly pass it to our *lda_model* to get the similarity scores for each topic. We represent each topic by printing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.7306936979293823\t \n",
      "Topic: 0.030*\"government\" + 0.020*\"health\" + 0.015*\"tasmania\" + 0.014*\"plan\" + 0.013*\"federal\" + 0.011*\"say\" + 0.011*\"care\" + 0.010*\"council\" + 0.010*\"call\" + 0.010*\"regional\"\n",
      "\n",
      "Score: 0.1692260056734085\t \n",
      "Topic: 0.035*\"coronavirus\" + 0.019*\"news\" + 0.018*\"china\" + 0.017*\"covid\" + 0.017*\"australia\" + 0.017*\"record\" + 0.016*\"market\" + 0.015*\"australian\" + 0.013*\"live\" + 0.011*\"coast\"\n",
      "\n",
      "Score: 0.012510393746197224\t \n",
      "Topic: 0.022*\"national\" + 0.017*\"change\" + 0.015*\"premier\" + 0.015*\"return\" + 0.014*\"tasmanian\" + 0.013*\"work\" + 0.012*\"rural\" + 0.011*\"show\" + 0.011*\"say\" + 0.011*\"risk\"\n",
      "\n",
      "Score: 0.012510163709521294\t \n",
      "Topic: 0.043*\"queensland\" + 0.026*\"south\" + 0.017*\"north\" + 0.016*\"victorian\" + 0.015*\"australia\" + 0.015*\"indigenous\" + 0.015*\"morrison\" + 0.013*\"west\" + 0.013*\"student\" + 0.013*\"school\"\n",
      "\n",
      "Score: 0.012510121800005436\t \n",
      "Topic: 0.040*\"trump\" + 0.020*\"vaccine\" + 0.017*\"australia\" + 0.015*\"test\" + 0.014*\"open\" + 0.013*\"world\" + 0.013*\"final\" + 0.012*\"royal\" + 0.010*\"interview\" + 0.009*\"pandemic\"\n",
      "\n",
      "Score: 0.012510061264038086\t \n",
      "Topic: 0.024*\"restriction\" + 0.024*\"canberra\" + 0.023*\"life\" + 0.019*\"water\" + 0.016*\"police\" + 0.015*\"missing\" + 0.015*\"country\" + 0.015*\"concern\" + 0.014*\"claim\" + 0.013*\"farmer\"\n",
      "\n",
      "Score: 0.01251005195081234\t \n",
      "Topic: 0.055*\"covid\" + 0.038*\"victoria\" + 0.037*\"coronavirus\" + 0.034*\"case\" + 0.023*\"child\" + 0.016*\"scott\" + 0.015*\"island\" + 0.012*\"border\" + 0.010*\"deal\" + 0.010*\"beach\"\n",
      "\n",
      "Score: 0.012509836815297604\t \n",
      "Topic: 0.036*\"police\" + 0.030*\"woman\" + 0.027*\"court\" + 0.024*\"death\" + 0.023*\"donald\" + 0.019*\"murder\" + 0.018*\"people\" + 0.016*\"year\" + 0.015*\"charged\" + 0.015*\"face\"\n",
      "\n",
      "Score: 0.012509834952652454\t \n",
      "Topic: 0.040*\"sydney\" + 0.030*\"election\" + 0.017*\"lockdown\" + 0.012*\"andrew\" + 0.011*\"state\" + 0.011*\"president\" + 0.011*\"commission\" + 0.010*\"say\" + 0.010*\"biden\" + 0.009*\"australia\"\n",
      "\n",
      "Score: 0.012509834952652454\t \n",
      "Topic: 0.021*\"crash\" + 0.017*\"house\" + 0.015*\"bushfire\" + 0.015*\"dy\" + 0.014*\"adelaide\" + 0.011*\"climate\" + 0.011*\"darwin\" + 0.009*\"home\" + 0.009*\"road\" + 0.009*\"week\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test document has the highest probability to be part of the topic that our model assigned, which is the accurate classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing our LDA model\n",
    "\n",
    "Now that we have a trained model let’s visualize the topics for interpretability. \n",
    "To do so, we’ll use a popular visualization package, *pyLDAvis* which is designed to help interactively with:\n",
    "\n",
    "1. Better understanding and interpreting individual topics, and\n",
    "2. Better understanding the relationships between the topics.\n",
    "\n",
    "For (1), you can manually select each topic to view its top most frequent and/or “relevant” terms, using different values of the λ parameter. This can help when you’re trying to assign a human interpretable name or “meaning” to each topic.\n",
    "For (2), exploring the Intertopic Distance Plot can help you learn about how topics relate to each other, including potential higher-level structure between groups of topics.\n",
    "\n",
    "You need to install *pyldavis* through the command line, following the instructions:\n",
    "\n",
    "https://anaconda.org/conda-forge/pyldavis\n",
    "\n",
    "WARNING: running the next cell takes a long time and you need some memory to run it. However, the result is spectacular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=96585) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/_utils.py:39: DeprecationWarning: Attribute n is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return node.n\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/_utils.py:38: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
      "  if isinstance(node, ast.Num):  # <number>\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/_utils.py:39: DeprecationWarning: Attribute n is deprecated and will be removed in Python 3.14; use value instead\n",
      "  return node.n\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=96585) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=96585) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=96585) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=96585) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=96585) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=96585) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=96585) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=96585) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=96585) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=96585) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=96585) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=96585) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "  pid = os.fork()\n",
      "/Users/axelehrnrooth/Library/Python/3.12/lib/python/site-packages/dateutil/tz/tz.py:37: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  EPOCH = datetime.datetime.utcfromtimestamp(0)\n",
      "/Users/axelehrnrooth/Library/Python/3.12/lib/python/site-packages/dateutil/tz/tz.py:37: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  EPOCH = datetime.datetime.utcfromtimestamp(0)\n",
      "/Users/axelehrnrooth/Library/Python/3.12/lib/python/site-packages/dateutil/tz/tz.py:37: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  EPOCH = datetime.datetime.utcfromtimestamp(0)\n",
      "/Users/axelehrnrooth/Library/Python/3.12/lib/python/site-packages/dateutil/tz/tz.py:37: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  EPOCH = datetime.datetime.utcfromtimestamp(0)\n",
      "/Users/axelehrnrooth/Library/Python/3.12/lib/python/site-packages/dateutil/tz/tz.py:37: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  EPOCH = datetime.datetime.utcfromtimestamp(0)\n",
      "/Users/axelehrnrooth/Library/Python/3.12/lib/python/site-packages/dateutil/tz/tz.py:37: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  EPOCH = datetime.datetime.utcfromtimestamp(0)\n",
      "/Users/axelehrnrooth/Library/Python/3.12/lib/python/site-packages/dateutil/tz/tz.py:37: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  EPOCH = datetime.datetime.utcfromtimestamp(0)\n",
      "/Users/axelehrnrooth/Library/Python/3.12/lib/python/site-packages/dateutil/tz/tz.py:37: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  EPOCH = datetime.datetime.utcfromtimestamp(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el96585126376898087428892649\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el96585126376898087428892649_data = {\"mdsDat\": {\"x\": [0.10537528332942342, 0.04234866904709586, 0.10995118803344378, -0.3139918918250082, -0.2866601970964225, 0.055702580258870524, 0.11003978772507172, 0.13231506478983102, -0.08498263323504297, 0.12990214897273766], \"y\": [-0.2587137728052525, 0.24076713636095193, 0.12077468400247802, 0.017654317492981342, 0.04036686507465236, 0.12295323679767009, 0.04910381672188544, -0.15666071694071385, -0.24325826854459312, 0.06701270183994036], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [13.294019528706686, 10.890098413367925, 10.812605026731672, 10.625070515272753, 9.848040099966356, 9.736491020524118, 9.254908817947873, 8.624408345952652, 8.528619082164141, 8.385739149365824]}, \"tinfo\": {\"Term\": [\"covid\", \"coronavirus\", \"trump\", \"queensland\", \"sydney\", \"police\", \"government\", \"victoria\", \"case\", \"woman\", \"election\", \"court\", \"south\", \"donald\", \"health\", \"death\", \"restriction\", \"canberra\", \"child\", \"life\", \"vaccine\", \"crash\", \"news\", \"national\", \"murder\", \"australia\", \"china\", \"people\", \"tasmania\", \"water\", \"government\", \"health\", \"tasmania\", \"federal\", \"plan\", \"care\", \"council\", \"regional\", \"aged\", \"speaks\", \"service\", \"public\", \"announces\", \"review\", \"funding\", \"budget\", \"mental\", \"emergency\", \"aboriginal\", \"finance\", \"action\", \"hong\", \"housing\", \"briefing\", \"told\", \"kong\", \"expert\", \"stop\", \"patient\", \"project\", \"call\", \"minister\", \"christmas\", \"group\", \"hospital\", \"say\", \"business\", \"labor\", \"worker\", \"change\", \"trump\", \"vaccine\", \"test\", \"final\", \"royal\", \"interview\", \"pandemic\", \"storm\", \"drum\", \"india\", \"beat\", \"black\", \"peter\", \"star\", \"hill\", \"outbreak\", \"alan\", \"lead\", \"break\", \"tuesday\", \"footage\", \"inquest\", \"thursday\", \"outback\", \"smith\", \"territory\", \"tour\", \"best\", \"play\", \"point\", \"open\", \"world\", \"league\", \"australia\", \"season\", \"australian\", \"news\", \"market\", \"live\", \"gold\", \"rise\", \"million\", \"price\", \"street\", \"industry\", \"rate\", \"wall\", \"video\", \"fall\", \"farm\", \"michael\", \"northern\", \"story\", \"trade\", \"flight\", \"share\", \"tourism\", \"dollar\", \"george\", \"turn\", \"building\", \"disability\", \"debate\", \"scientist\", \"spring\", \"positive\", \"number\", \"quarantine\", \"record\", \"china\", \"coronavirus\", \"coast\", \"high\", \"covid\", \"australian\", \"australia\", \"business\", \"year\", \"court\", \"donald\", \"murder\", \"people\", \"charged\", \"face\", \"charge\", \"accused\", \"victim\", \"alleged\", \"shooting\", \"assault\", \"baby\", \"arrested\", \"food\", \"jailed\", \"jail\", \"sentenced\", \"appeal\", \"mother\", \"arrest\", \"teen\", \"kid\", \"get\", \"rape\", \"result\", \"guilty\", \"killing\", \"online\", \"challenge\", \"drug\", \"trial\", \"woman\", \"death\", \"police\", \"hotel\", \"year\", \"family\", \"case\", \"crash\", \"house\", \"bushfire\", \"dy\", \"climate\", \"darwin\", \"week\", \"mark\", \"near\", \"close\", \"look\", \"david\", \"station\", \"testing\", \"free\", \"white\", \"friday\", \"find\", \"girl\", \"monday\", \"train\", \"bushfires\", \"rescue\", \"plane\", \"month\", \"light\", \"truck\", \"festival\", \"start\", \"owner\", \"adelaide\", \"road\", \"home\", \"woman\", \"police\", \"year\", \"driver\", \"death\", \"sydney\", \"election\", \"lockdown\", \"andrew\", \"president\", \"commission\", \"biden\", \"liberal\", \"travel\", \"medium\", \"right\", \"player\", \"international\", \"social\", \"shot\", \"kill\", \"security\", \"issue\", \"wednesday\", \"russia\", \"airport\", \"rugby\", \"leave\", \"mask\", \"global\", \"human\", \"paul\", \"america\", \"military\", \"cause\", \"leader\", \"dead\", \"state\", \"say\", \"warning\", \"australia\", \"china\", \"win\", \"australian\", \"queensland\", \"south\", \"north\", \"indigenous\", \"morrison\", \"west\", \"student\", \"killed\", \"city\", \"update\", \"program\", \"centre\", \"town\", \"bank\", \"east\", \"protester\", \"korea\", \"latest\", \"sport\", \"meet\", \"head\", \"extended\", \"hour\", \"central\", \"great\", \"refugee\", \"prince\", \"youth\", \"economy\", \"university\", \"victorian\", \"protest\", \"attack\", \"community\", \"school\", \"australia\", \"australian\", \"coast\", \"coronavirus\", \"national\", \"premier\", \"return\", \"tasmanian\", \"work\", \"rural\", \"show\", \"risk\", \"young\", \"park\", \"parliament\", \"weather\", \"sexual\", \"cricket\", \"law\", \"history\", \"club\", \"turnbull\", \"rollout\", \"study\", \"join\", \"indonesia\", \"union\", \"tree\", \"kohler\", \"money\", \"data\", \"mount\", \"recovery\", \"politics\", \"change\", \"worker\", \"say\", \"australia\", \"australian\", \"canberra\", \"restriction\", \"life\", \"water\", \"missing\", \"country\", \"concern\", \"claim\", \"officer\", \"john\", \"party\", \"search\", \"river\", \"western\", \"campaign\", \"crisis\", \"investigation\", \"fatal\", \"continues\", \"hold\", \"day\", \"opposition\", \"authority\", \"killer\", \"inside\", \"left\", \"lake\", \"russian\", \"robert\", \"probe\", \"continue\", \"farmer\", \"amid\", \"police\", \"question\", \"long\", \"crime\", \"victoria\", \"child\", \"scott\", \"deal\", \"beach\", \"abuse\", \"second\", \"violence\", \"daniel\", \"zealand\", \"body\", \"energy\", \"johnson\", \"post\", \"domestic\", \"facebook\", \"coal\", \"prime\", \"allegation\", \"james\", \"lawyer\", \"pacific\", \"ship\", \"make\", \"research\", \"sign\", \"come\", \"economic\", \"target\", \"bos\", \"island\", \"case\", \"covid\", \"coronavirus\", \"border\", \"minister\", \"australia\", \"say\"], \"Freq\": [37346.0, 44833.0, 24581.0, 22529.0, 21713.0, 33610.0, 22296.0, 17991.0, 20156.0, 22173.0, 16477.0, 15863.0, 13356.0, 13832.0, 15315.0, 17550.0, 11331.0, 11329.0, 11055.0, 10964.0, 12153.0, 11436.0, 11842.0, 10500.0, 11256.0, 43765.0, 14366.0, 10490.0, 11582.0, 9056.0, 22295.706303419323, 15314.275293214732, 11581.24198606873, 9961.335175138915, 10355.120496936286, 7913.708617555185, 7838.064362257553, 7179.417228997011, 6763.215363445496, 6731.483378117606, 6713.8847578991, 5868.482315068145, 5559.845450772217, 5513.402673905704, 5288.071587233597, 6453.567828764979, 5138.333212366041, 5036.815864876272, 4904.257841746212, 4893.775357974408, 4388.937142467394, 4037.216535026307, 4028.235081357047, 3922.4312655373215, 3855.521890982592, 3791.412581862771, 3679.1362267261584, 3637.634659858461, 3619.096415691773, 3527.119838424556, 7437.438383087983, 6984.216448432005, 4425.3198832452545, 4134.8308559826155, 5604.2038505705805, 8387.36406454909, 4740.02808345247, 4375.186522620816, 4342.638199807921, 4307.277273953695, 24580.428130505952, 12152.700521445606, 9049.506783301968, 7818.423752018428, 7084.247519751824, 6057.2757241159115, 5662.59372031148, 5578.872880293756, 5255.243097413934, 5143.013727721465, 4669.541277881365, 4504.533698149985, 3924.6826204172085, 3839.4988096588295, 3670.992139417674, 3666.4078030620635, 3645.72479745443, 3635.753887277779, 3445.5659792485008, 3344.2492643533724, 3332.945761288735, 3309.7233831064987, 3215.624523074582, 3206.360848558244, 2947.529429035584, 2824.348319719045, 2838.5997316493563, 2618.0891303455246, 2591.2039047882377, 2515.171649298717, 8832.574583324194, 7917.945132500347, 3779.018321137823, 10656.7604456368, 3572.704070658034, 5158.845079581914, 11842.081815160975, 9629.486877122425, 8069.083589331804, 6481.010840403578, 6253.36110095078, 5910.043598360708, 5777.056716113712, 5763.341804775281, 5071.682889737263, 4667.215940350407, 4336.264462160157, 4323.2285264605, 4285.401623758085, 4189.272043207444, 4052.0291705672084, 4035.9198574454776, 3938.711620560896, 3851.386912248757, 3612.632507811852, 3490.148928312369, 3278.9495477339456, 3073.169508799681, 2964.4909175068533, 2706.8790056856396, 2683.221930832242, 2651.677181536902, 2649.5623579578046, 2470.9133017759527, 2383.6922668404486, 2322.9442003023823, 3545.2932505609524, 5239.289315004633, 10284.771733033862, 10715.589565503049, 21478.012304227854, 6843.298871354125, 4552.772712751899, 10502.895985302373, 9246.014919546325, 10420.07738648612, 4078.197633828358, 4169.876340698534, 15862.631382815418, 13831.511499601565, 11255.80767736716, 10490.145519244345, 9049.050394117136, 8851.500906274867, 6791.71287982912, 6207.482207509754, 6026.972609295717, 5723.384894245557, 5092.063357681945, 4941.300221697807, 4696.211729810882, 4639.147945747467, 4027.3728198696544, 3956.6544109311603, 3832.8640023253183, 3812.1680156297725, 3786.059001171147, 3757.4298266175488, 3663.732979826145, 3548.3252906172747, 3325.8191478031476, 3195.971058156121, 3105.8264847391415, 3084.7157599674406, 5963.7526091045675, 3020.6111707789614, 2983.1099415680687, 2910.7239515461883, 5766.671302097261, 7899.553435119076, 17888.93251061021, 14154.165475551372, 21761.04966258355, 4673.985665796797, 9636.097945181931, 5379.657770463835, 3902.567555541892, 11435.990119746568, 9342.286855281667, 8442.400158889955, 8411.345705581522, 6359.484040738357, 6038.496522184058, 4745.645220517767, 4712.555729179117, 4624.887075132049, 4453.323668699421, 4320.8689564810675, 4285.122925259417, 4238.572204293168, 4049.9988932702627, 3970.1633812963905, 3965.3255221251707, 3924.12890159516, 3879.7938128048095, 3866.330519244116, 3728.4151560435716, 3661.204464811149, 3504.076206434627, 3499.6093392369676, 3263.0926683929583, 3223.318613747659, 3219.4479652223918, 3200.8315467104426, 3168.6019414968832, 3114.252649336755, 3055.171532568086, 7960.215853848525, 4769.309761384839, 4974.3878293733815, 4283.828065234867, 4177.171742710652, 3680.756618989374, 3352.5337249840904, 3394.7318690477337, 21713.150378308965, 16476.56832105176, 9246.35294801926, 6725.954477696975, 5814.571770452268, 5809.6953544890275, 5243.384246864264, 4932.569482139554, 4914.61668053077, 4689.019567634435, 4105.580807770126, 4021.3127791571046, 3938.0122286144137, 3857.2437515766446, 3555.629593620951, 3448.4826089113294, 3392.8927932910406, 3358.6321323554544, 3216.758219926023, 3168.4906803312983, 3033.3365701066778, 2993.0960631703483, 2778.57559216227, 2657.6446594113513, 2651.5584494888235, 2597.3551908920813, 2514.43214299745, 2497.78172552447, 2470.9030268439396, 2424.263850023006, 4436.007600269583, 4898.153994104392, 6139.342399964757, 5443.4606503356545, 3117.366874079164, 4950.373323243969, 3650.459279090856, 3031.266682276272, 3489.179945065682, 22528.61393088746, 13356.057609226193, 8663.04862970534, 7962.814624099851, 7935.305396386318, 6634.616100117544, 6608.84041295637, 5799.110167186505, 4894.277159354551, 4762.921336504763, 4651.936433544374, 4507.545355553742, 4366.222765567399, 4093.305293852298, 3713.489953175566, 3533.162700761143, 3506.99739126883, 3420.213199325822, 3392.3953286580017, 3377.1132594893666, 3351.4229158630774, 3111.6197054963964, 2990.579055066205, 2990.2708970183658, 2955.229132538302, 2927.850102206114, 2904.445365123474, 2851.7547031010504, 2783.2066304091877, 2720.7455883617345, 8441.432805491757, 5743.303738781094, 6322.31937574312, 5575.757892981876, 6550.7112826640205, 8060.25318052298, 4949.528854783208, 3773.3683834798408, 4793.551422118991, 10499.223179296558, 7320.9073341044605, 7051.620731120954, 6560.64226572851, 6121.5793379387205, 5849.027962049137, 5507.890598446037, 5293.5009824263325, 5280.46448438615, 5247.550151032705, 5068.970462107918, 4766.716204912431, 4578.939119761999, 4336.8990236183145, 3894.9499913923846, 3678.6622883703303, 3601.2385942904393, 3206.6920312381744, 3190.571508964916, 3173.186649724017, 3110.4182839868718, 3108.7901903148168, 3008.9936514267283, 2988.708001920008, 2954.217540137996, 2952.269069443047, 2797.672018195371, 2787.881766322283, 2723.4021625235027, 2599.7732332927353, 8050.208799180326, 5131.24696551866, 5331.791233186504, 5176.188315573578, 3038.892870978679, 11328.242580394479, 11330.307040564223, 10963.987798115631, 9055.870716325544, 7418.246623732706, 7372.361538769456, 7053.630784350579, 6846.447013319796, 5761.4900794888335, 5602.618251252876, 5588.696550692618, 5562.6150903619955, 5096.9425851123215, 4952.772215660909, 4771.023308885938, 4696.553940775887, 4511.6944913079315, 4062.510409392328, 3253.448692295871, 2947.6726488685663, 2815.5675298096185, 2708.99960430927, 2689.005843788715, 2659.115409759628, 2656.8257357531843, 2556.573628443132, 2521.934936023633, 2408.5252465278386, 2324.0671532220335, 2275.3532662880975, 2542.5504922857895, 6395.716820541136, 4809.5965406549185, 7622.471335186857, 3188.890520411996, 2938.4659161613517, 2794.9673899708073, 17990.186939155872, 11054.50109617667, 7413.204539239288, 4654.662518531308, 4566.119578445593, 4489.841999882242, 4196.03395528786, 4174.15393170095, 3691.926542238573, 3685.6121833361995, 3527.3626137574774, 3000.001716735876, 2969.1241216510534, 2948.266065068765, 2928.3038772407426, 2920.5035800711166, 2904.1738566501062, 2787.2935202058025, 2670.245565355539, 2651.422875131337, 2581.928240083613, 2563.082263422935, 2507.2648948715005, 2423.3164126393235, 2327.0505039277546, 2289.4965117583542, 2232.041184052479, 2180.715681224067, 2156.083464465639, 2049.535934999491, 7165.934218260352, 16252.959024114734, 25878.578894807215, 17543.623386207742, 5512.171921419543, 3360.7973698395585, 4501.33803026742, 4133.929468571064], \"Total\": [37346.0, 44833.0, 24581.0, 22529.0, 21713.0, 33610.0, 22296.0, 17991.0, 20156.0, 22173.0, 16477.0, 15863.0, 13356.0, 13832.0, 15315.0, 17550.0, 11331.0, 11329.0, 11055.0, 10964.0, 12153.0, 11436.0, 11842.0, 10500.0, 11256.0, 43765.0, 14366.0, 10490.0, 11582.0, 9056.0, 22296.522251555052, 15315.09124402022, 11582.057963187683, 9962.151131388002, 10355.983908632443, 7914.524566867338, 7838.882581112879, 7180.233219760722, 6764.031347257952, 6732.299344420366, 6714.700686435684, 5869.298248079251, 5560.661440384889, 5514.219620478756, 5288.8875018689505, 6454.566994132563, 5139.149127144239, 5037.631846553257, 4905.073807567973, 4894.591362731762, 4389.753085427042, 4038.0325104507847, 4029.0518496337268, 3923.247620040729, 3856.337879744135, 3792.228559874066, 3679.952289523412, 3638.450630569605, 3619.924238522296, 3527.9428708877945, 10859.67260174448, 10345.749885175965, 5310.461935619607, 4657.741304234398, 9546.32044741909, 31635.008528215665, 8819.082896669965, 7755.421208277182, 9474.605411030454, 12358.206311885819, 24581.25825177047, 12153.530912960043, 9050.336752515052, 7819.253671437219, 7085.077538854093, 6058.105633529142, 5663.42661314663, 5579.702857708623, 5256.073013649462, 5143.843699120654, 4670.371207530284, 4505.363714052088, 3925.512610926057, 3840.328759434192, 3671.822099913253, 3667.2379008736857, 3646.5548323179332, 3636.583840856272, 3446.3959429597526, 3345.0791850080072, 3333.775794168314, 3310.5533706021165, 3216.454445369256, 3207.1908393597, 2948.3593734597907, 2825.178341149672, 2839.434594374628, 2618.919084690839, 2592.033841156437, 2516.0016159414567, 10448.358826532452, 12637.609968745453, 4600.9916305371, 43765.386787865486, 4840.1397652148435, 29671.170151938655, 11842.92053624608, 9630.325554278468, 8069.922298727316, 6481.849537403984, 6254.199800015504, 5910.882328672377, 5777.895394501782, 5764.180517115792, 5072.5215987463525, 4668.054635883652, 4337.103137507478, 4324.067299090245, 4286.240314651757, 4190.110755733872, 4052.867913124715, 4036.7587107887452, 3939.550323265227, 3852.225608613023, 3613.4712514618436, 3490.9875964604016, 3279.78827951885, 3074.008177313779, 2965.329707556888, 2707.717738080563, 2684.06065586485, 2652.5159665842325, 2650.401087369699, 2471.752036432005, 2384.530961006005, 2323.7830135519325, 3546.9847252498785, 5756.690552778026, 12360.122283485884, 14366.797258046307, 44833.09135317599, 10617.420274572962, 6810.406100214646, 37346.778766461255, 29671.170151938655, 43765.386787865486, 8819.082896669965, 19615.114986610246, 15863.459655766657, 13832.339937384731, 11256.635924126487, 10490.97386584599, 9049.878646244371, 8852.329213151463, 6792.541139932719, 6208.310470909337, 6027.800906838636, 5724.213160313446, 5092.891793473129, 4942.1284899040875, 4697.040018558866, 4639.980274309634, 4028.2011214172903, 3957.4864893614404, 3833.692264064306, 3812.9962836131567, 3786.8872751365943, 3758.2581049935316, 3664.5617076534945, 3549.153562912939, 3326.647468228804, 3196.7993587663746, 3106.654770165447, 3085.5441033506686, 5965.37370968235, 3021.4394564524564, 2983.938270311238, 2911.552256412433, 5848.6587893084925, 8600.423594302698, 22173.87055058899, 17550.98162927718, 33610.965315583104, 5744.255576844502, 19615.114986610246, 12272.873778439494, 20156.274653185836, 11436.934335876644, 9343.11223924447, 8443.225654790573, 8412.171062645746, 6360.309461391822, 6039.321899600979, 4746.470592429456, 4713.38112649831, 4625.712428878917, 4454.149047924536, 4321.694348742755, 4285.948300362813, 4239.397560306918, 4050.824356142328, 3970.9887629833142, 3966.1508923105885, 3924.9542552407493, 3880.619206578832, 3867.155886599334, 3729.2405102786797, 3662.029864341579, 3504.901643424502, 3500.4416354289806, 3263.9180228994187, 3224.1440012806997, 3220.2733239426307, 3201.6568911423324, 3169.427284852147, 3115.0780083682334, 3055.996908608432, 10727.65120158366, 5667.274932775377, 13947.284188983469, 22173.87055058899, 33610.965315583104, 19615.114986610246, 5715.585265821043, 17550.98162927718, 21713.98057544006, 16477.398880388457, 9247.18362732402, 6726.784712018876, 5815.401925594962, 5810.525559375894, 5244.214667618448, 4933.39964509465, 4915.446946050299, 4689.849728527237, 4106.410967795526, 4022.142958570624, 3938.843163356502, 3858.0739124888178, 3556.459757711279, 3449.312765179753, 3393.722963984056, 3359.4624284330225, 3217.5883527474075, 3169.320836017723, 3034.166731121201, 2993.9262133047478, 2779.4072342725285, 2658.475116787609, 2652.3889895013713, 2598.1853408954903, 2515.262326767785, 2498.611888826367, 2471.7331873994494, 2425.094016713953, 5434.859536407537, 7071.502356386598, 11838.452929508208, 31635.008528215665, 5074.724539924616, 43765.386787865486, 14366.797258046307, 5954.42612015012, 29671.170151938655, 22529.448785148983, 13356.89240550064, 8663.883405149743, 7963.649443990138, 7936.140369842255, 6635.450895258699, 6609.67520577725, 5799.944980899137, 4895.11197879864, 4763.756257863527, 4652.771228177677, 4508.380148131243, 4367.057584274734, 4094.140091054547, 3714.3247441394037, 3534.000044523914, 3507.832148854524, 3421.0480898245505, 3393.230150498744, 3377.9480624612047, 3352.2577211294247, 3112.4545129253793, 2991.4138240624625, 2991.10569112695, 2956.06395646613, 2928.684890549874, 2905.2802237785254, 2852.5894963630644, 2784.041471054757, 2721.5803913507198, 8473.935207877345, 7257.339283539267, 9185.322252336924, 8185.457500386871, 11293.260233095649, 43765.386787865486, 29671.170151938655, 10617.420274572962, 44833.09135317599, 10500.048631798642, 7321.732161692748, 7052.445530117435, 6561.467125181739, 6122.404118934794, 5849.852697191502, 5508.715401233317, 5294.325782747003, 5281.2892762175, 5248.374925385173, 5069.79524705098, 4767.541224486167, 4579.763959123797, 4337.723818790975, 3895.77475659155, 3679.4870728598917, 3602.156273055116, 3207.516780742044, 3191.396771770301, 3174.0114193066916, 3111.2431126762094, 3109.614976434956, 3009.8184248241037, 2989.532788332816, 2955.0424428260235, 2953.0938544541823, 2798.4968098976096, 2788.7065885326697, 2724.2270022040934, 2600.5980250225075, 12358.206311885819, 9474.605411030454, 31635.008528215665, 43765.386787865486, 29671.170151938655, 11329.059030992214, 11331.123820878664, 10964.804257795631, 9056.687143485702, 7419.063053771655, 7373.177959725916, 7054.447234819015, 6847.263454750699, 5762.306538212499, 5603.434695721345, 5589.5130044324715, 5563.43151092421, 5097.759011285056, 4953.588681587733, 4771.839749627118, 4697.370400884719, 4512.510934846868, 4063.3268658039788, 3254.2651473803553, 2948.489085530264, 2816.3839928192483, 2709.8160460971594, 2689.8223040027615, 2659.93188330211, 2657.6422052358657, 2557.3900983861377, 2522.751366987984, 2409.341689669131, 2324.883604202161, 2276.1699378691396, 2562.708236354175, 9194.780842198139, 6714.017224684946, 33610.965315583104, 4517.825782916866, 4101.1061150213245, 3673.6695217094434, 17991.027236823145, 11055.34133587458, 7414.04484275014, 4655.502752952196, 4566.959844994012, 4490.6823191236645, 4196.874202061135, 4174.994154346326, 3692.7668306794135, 3686.4524341762813, 3528.202850443795, 3000.8420179490695, 2969.964354053733, 2949.1063125051264, 2929.1440912879348, 2921.343838696436, 2905.0140913327227, 2788.1337439599156, 2671.085840794519, 2652.263113253148, 2582.768485775999, 2563.9224811893455, 2508.1051419023493, 2424.156655100099, 2327.8909777035346, 2290.3367381523753, 2232.8814230551893, 2181.555927759004, 2156.923706620478, 2050.3761805008894, 7168.929970760902, 20156.274653185836, 37346.778766461255, 44833.09135317599, 9826.289174971229, 10345.749885175965, 43765.386787865486, 31635.008528215665], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.5129, -3.8885, -4.1679, -4.3186, -4.2798, -4.5487, -4.5583, -4.646, -4.7058, -4.7105, -4.7131, -4.8477, -4.9017, -4.9101, -4.9518, -4.7526, -4.9805, -5.0005, -5.0272, -5.0293, -5.1382, -5.2217, -5.2239, -5.2506, -5.2678, -5.2845, -5.3146, -5.3259, -5.331, -5.3568, -4.6107, -4.6736, -5.1299, -5.1978, -4.8937, -4.4905, -5.0612, -5.1413, -5.1488, -5.157, -3.2159, -3.9203, -4.2151, -4.3613, -4.4599, -4.6165, -4.6839, -4.6988, -4.7586, -4.7802, -4.8767, -4.9127, -5.0505, -5.0725, -5.1173, -5.1186, -5.1243, -5.127, -5.1807, -5.2106, -5.2139, -5.2209, -5.2498, -5.2527, -5.3368, -5.3795, -5.3745, -5.4554, -5.4657, -5.4955, -4.2394, -4.3487, -5.0883, -4.0516, -5.1445, -4.7771, -3.939, -4.1458, -4.3226, -4.5418, -4.5775, -4.634, -4.6568, -4.6591, -4.787, -4.8701, -4.9437, -4.9467, -4.9554, -4.9781, -5.0114, -5.0154, -5.0398, -5.0622, -5.1262, -5.1607, -5.2231, -5.288, -5.324, -5.4149, -5.4236, -5.4355, -5.4363, -5.5061, -5.542, -5.5678, -5.145, -4.7545, -4.08, -4.039, -3.3436, -4.4874, -4.8949, -4.059, -4.1865, -4.0669, -5.005, -4.9828, -3.6292, -3.7662, -3.9723, -4.0427, -4.1905, -4.2126, -4.4775, -4.5674, -4.5969, -4.6486, -4.7655, -4.7955, -4.8464, -4.8586, -5.0001, -5.0178, -5.0496, -5.055, -5.0618, -5.0694, -5.0947, -5.1267, -5.1915, -5.2313, -5.2599, -5.2667, -4.6075, -5.2877, -5.3002, -5.3248, -4.6411, -4.3264, -3.509, -3.7432, -3.313, -4.8512, -4.1277, -4.7105, -5.0315, -3.8805, -4.0827, -4.184, -4.1876, -4.4673, -4.5191, -4.76, -4.767, -4.7858, -4.8236, -4.8538, -4.8621, -4.873, -4.9185, -4.9384, -4.9396, -4.9501, -4.9614, -4.9649, -5.0012, -5.0194, -5.0633, -5.0646, -5.1345, -5.1468, -5.148, -5.1538, -5.1639, -5.1812, -5.2004, -4.2428, -4.755, -4.7129, -4.8624, -4.8876, -5.0141, -5.1075, -5.095, -3.2279, -3.5039, -4.0816, -4.3999, -4.5455, -4.5463, -4.6489, -4.71, -4.7136, -4.7606, -4.8935, -4.9142, -4.9352, -4.9559, -5.0373, -5.0679, -5.0841, -5.0943, -5.1375, -5.1526, -5.1962, -5.2095, -5.2839, -5.3284, -5.3307, -5.3513, -5.3838, -5.3904, -5.4012, -5.4203, -4.8161, -4.717, -4.4911, -4.6114, -5.1688, -4.7064, -5.011, -5.1969, -5.0562, -3.1403, -3.6631, -4.096, -4.1803, -4.1838, -4.3628, -4.3667, -4.4974, -4.667, -4.6942, -4.7178, -4.7494, -4.7812, -4.8458, -4.9431, -4.9929, -5.0003, -5.0254, -5.0336, -5.0381, -5.0457, -5.12, -5.1596, -5.1597, -5.1715, -5.1808, -5.1889, -5.2072, -5.2315, -5.2542, -4.122, -4.5071, -4.411, -4.5367, -4.3755, -4.1682, -4.6558, -4.9271, -4.6878, -3.8332, -4.1938, -4.2313, -4.3035, -4.3727, -4.4183, -4.4784, -4.5181, -4.5205, -4.5268, -4.5614, -4.6229, -4.6631, -4.7174, -4.8249, -4.882, -4.9033, -5.0193, -5.0243, -5.0298, -5.0498, -5.0503, -5.0829, -5.0897, -5.1013, -5.102, -5.1558, -5.1593, -5.1827, -5.2291, -4.0988, -4.5492, -4.5109, -4.5405, -5.0731, -3.7461, -3.7459, -3.7788, -3.97, -4.1694, -4.1756, -4.2198, -4.2496, -4.4222, -4.4501, -4.4526, -4.4573, -4.5447, -4.5734, -4.6108, -4.6265, -4.6667, -4.7716, -4.9937, -5.0924, -5.1382, -5.1768, -5.1842, -5.1954, -5.1962, -5.2347, -5.2484, -5.2944, -5.3301, -5.3512, -5.2402, -4.3178, -4.6028, -4.1423, -5.0137, -5.0955, -5.1456, -3.2667, -3.7536, -4.1532, -4.6186, -4.6378, -4.6547, -4.7223, -4.7276, -4.8503, -4.852, -4.8959, -5.0579, -5.0682, -5.0753, -5.0821, -5.0847, -5.0903, -5.1314, -5.1743, -5.1814, -5.2079, -5.2153, -5.2373, -5.2713, -5.3119, -5.3282, -5.3536, -5.3768, -5.3882, -5.4389, -4.1871, -3.3682, -2.9031, -3.2918, -4.4495, -4.9443, -4.6521, -4.7373], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.0178, 2.0178, 2.0178, 2.0178, 2.0178, 2.0178, 2.0178, 2.0177, 2.0177, 2.0177, 2.0177, 2.0177, 2.0177, 2.0177, 2.0177, 2.0177, 2.0177, 2.0177, 2.0177, 2.0177, 2.0177, 2.0177, 2.0177, 2.0176, 2.0176, 2.0176, 2.0176, 2.0176, 2.0176, 2.0176, 1.6393, 1.6249, 1.8355, 1.8988, 1.4852, 0.6903, 1.397, 1.4454, 1.2377, 0.9638, 2.2173, 2.2172, 2.2172, 2.2172, 2.2172, 2.2172, 2.2172, 2.2172, 2.2172, 2.2172, 2.2171, 2.2171, 2.2171, 2.2171, 2.2171, 2.2171, 2.2171, 2.2171, 2.2171, 2.2171, 2.2171, 2.2171, 2.2171, 2.2171, 2.217, 2.217, 2.217, 2.217, 2.217, 2.217, 2.0493, 1.7498, 2.0205, 0.8047, 1.9137, 0.4679, 2.2244, 2.2244, 2.2244, 2.2243, 2.2243, 2.2243, 2.2243, 2.2243, 2.2243, 2.2243, 2.2243, 2.2243, 2.2243, 2.2243, 2.2243, 2.2242, 2.2242, 2.2242, 2.2242, 2.2242, 2.2242, 2.2242, 2.2242, 2.2241, 2.2241, 2.2241, 2.2241, 2.2241, 2.2241, 2.2241, 2.224, 2.1303, 2.0406, 1.9312, 1.4885, 1.7852, 1.8217, 0.9559, 1.0585, 0.7893, 1.4532, 0.676, 2.2419, 2.2419, 2.2419, 2.2419, 2.2419, 2.2419, 2.2418, 2.2418, 2.2418, 2.2418, 2.2418, 2.2418, 2.2418, 2.2418, 2.2417, 2.2417, 2.2417, 2.2417, 2.2417, 2.2417, 2.2417, 2.2417, 2.2417, 2.2417, 2.2417, 2.2417, 2.2417, 2.2417, 2.2417, 2.2417, 2.2278, 2.1569, 2.0272, 2.0269, 1.8072, 2.0358, 1.5312, 1.4172, 0.6001, 2.3178, 2.3178, 2.3178, 2.3178, 2.3178, 2.3178, 2.3177, 2.3177, 2.3177, 2.3177, 2.3177, 2.3177, 2.3177, 2.3177, 2.3177, 2.3177, 2.3177, 2.3177, 2.3177, 2.3177, 2.3177, 2.3177, 2.3177, 2.3176, 2.3176, 2.3176, 2.3176, 2.3176, 2.3176, 2.3176, 2.0195, 2.1454, 1.2869, 0.6738, 0.2327, 0.6447, 1.7844, 0.675, 2.3293, 2.3292, 2.3292, 2.3292, 2.3291, 2.3291, 2.3291, 2.3291, 2.3291, 2.3291, 2.3291, 2.3291, 2.3291, 2.3291, 2.3291, 2.329, 2.329, 2.329, 2.329, 2.329, 2.329, 2.329, 2.329, 2.329, 2.329, 2.329, 2.329, 2.329, 2.329, 2.3289, 2.1262, 1.9621, 1.6727, 0.5694, 1.842, 0.1499, 0.9592, 1.6541, 0.1888, 2.38, 2.38, 2.3799, 2.3799, 2.3799, 2.3799, 2.3799, 2.3799, 2.3798, 2.3798, 2.3798, 2.3798, 2.3798, 2.3798, 2.3798, 2.3798, 2.3798, 2.3798, 2.3798, 2.3798, 2.3798, 2.3797, 2.3797, 2.3797, 2.3797, 2.3797, 2.3797, 2.3797, 2.3797, 2.3797, 2.3762, 2.146, 2.0065, 1.9961, 1.8354, 0.6881, 0.5891, 1.3455, 0.1443, 2.4505, 2.4505, 2.4505, 2.4504, 2.4504, 2.4504, 2.4504, 2.4504, 2.4504, 2.4504, 2.4504, 2.4504, 2.4504, 2.4504, 2.4504, 2.4503, 2.4503, 2.4503, 2.4503, 2.4503, 2.4503, 2.4503, 2.4503, 2.4503, 2.4503, 2.4503, 2.4503, 2.4503, 2.4503, 2.4503, 2.022, 1.8373, 0.67, 0.3158, 0.1719, 2.4617, 2.4617, 2.4617, 2.4617, 2.4616, 2.4616, 2.4616, 2.4616, 2.4616, 2.4616, 2.4616, 2.4616, 2.4616, 2.4616, 2.4616, 2.4616, 2.4616, 2.4615, 2.4615, 2.4615, 2.4615, 2.4614, 2.4614, 2.4614, 2.4614, 2.4614, 2.4614, 2.4614, 2.4614, 2.4614, 2.4538, 2.0987, 2.1282, 0.978, 2.1134, 2.1284, 2.1884, 2.4786, 2.4786, 2.4785, 2.4785, 2.4785, 2.4785, 2.4784, 2.4784, 2.4784, 2.4784, 2.4784, 2.4784, 2.4784, 2.4784, 2.4784, 2.4783, 2.4783, 2.4783, 2.4783, 2.4783, 2.4783, 2.4783, 2.4783, 2.4783, 2.4783, 2.4783, 2.4783, 2.4783, 2.4782, 2.4782, 2.4782, 2.2634, 2.1118, 1.5404, 1.9005, 1.3542, 0.2042, 0.4436]}, \"token.table\": {\"Topic\": [1, 10, 4, 1, 2, 5, 1, 6, 2, 10, 4, 6, 3, 9, 6, 1, 4, 4, 4, 4, 6, 7, 2, 3, 6, 7, 8, 10, 2, 3, 4, 5, 6, 7, 8, 9, 4, 7, 10, 2, 2, 6, 2, 10, 6, 7, 10, 10, 2, 1, 1, 3, 5, 5, 1, 3, 1, 6, 7, 9, 10, 9, 9, 1, 4, 10, 6, 7, 7, 4, 1, 8, 4, 4, 10, 3, 6, 1, 7, 7, 9, 5, 5, 8, 10, 3, 7, 10, 6, 1, 7, 9, 5, 9, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 9, 4, 1, 2, 3, 5, 6, 7, 8, 9, 10, 5, 8, 7, 9, 9, 10, 5, 8, 5, 9, 5, 6, 10, 4, 5, 9, 3, 3, 3, 10, 4, 4, 5, 2, 4, 2, 5, 7, 10, 7, 6, 1, 10, 1, 7, 4, 10, 3, 1, 4, 5, 6, 7, 8, 10, 3, 1, 9, 9, 1, 5, 2, 1, 5, 3, 4, 2, 5, 5, 1, 3, 4, 5, 6, 3, 1, 7, 1, 7, 8, 4, 10, 7, 1, 3, 4, 2, 8, 9, 2, 4, 5, 6, 7, 8, 10, 1, 1, 4, 5, 7, 9, 1, 4, 5, 6, 7, 5, 1, 6, 2, 7, 8, 3, 2, 9, 6, 2, 9, 1, 10, 6, 4, 4, 10, 9, 10, 8, 4, 6, 7, 9, 4, 8, 1, 7, 1, 6, 8, 9, 7, 8, 10, 2, 6, 7, 2, 6, 6, 9, 6, 9, 5, 3, 6, 5, 9, 5, 10, 5, 3, 6, 6, 7, 1, 3, 6, 3, 1, 10, 9, 5, 8, 5, 7, 4, 8, 4, 8, 5, 3, 7, 3, 3, 8, 9, 4, 2, 10, 9, 2, 2, 5, 10, 2, 8, 8, 9, 1, 6, 4, 2, 1, 5, 2, 6, 2, 4, 5, 7, 9, 10, 8, 3, 10, 8, 6, 3, 10, 7, 9, 7, 1, 7, 8, 7, 1, 1, 3, 7, 7, 1, 9, 4, 3, 2, 3, 8, 7, 1, 5, 10, 9, 4, 8, 1, 6, 3, 8, 9, 1, 5, 9, 9, 8, 2, 6, 8, 6, 9, 1, 2, 3, 5, 6, 7, 8, 9, 10, 1, 4, 5, 7, 10, 3, 10, 9, 2, 5, 10, 6, 4, 1, 8, 3, 10, 4, 6, 8, 10, 2, 6, 7, 1, 7, 3, 2, 5, 1, 6, 9, 5, 1, 2, 3, 3, 7, 8, 6, 10, 1, 8, 4, 2, 2, 5, 2, 1, 2, 3, 7, 3, 5, 6, 8, 4, 10, 5, 2, 2, 3, 8, 8, 7, 7, 2, 4, 10, 5, 7, 3, 10, 3, 5, 6, 9, 8, 6, 5, 7, 9, 5, 2, 6, 4, 5, 8, 1, 8, 2, 3, 6, 3, 4, 5, 10, 8, 7, 10], \"Freq\": [0.9997810822813071, 0.999848058919519, 0.9997889166600998, 0.9998284446955475, 0.2579315777522226, 0.7420077191570986, 0.9998475247666659, 0.9996154690151883, 0.9998478475318632, 0.9995934833774582, 0.9997880651402263, 0.9997551084947994, 0.28358580806133465, 0.7164116264574684, 0.9998833451563458, 0.9998810500527716, 0.9997656980332053, 0.9998467190080819, 0.9997887330868491, 0.9997716591330248, 0.31158406002270106, 0.688271987233933, 0.24350293193238245, 0.23808769360377455, 0.11310307901522879, 0.18416380138641295, 0.11826697716824731, 0.10284383002980703, 0.17387248206194933, 0.31161561720193515, 0.057968728270314566, 0.06969728492035496, 0.1175888912413532, 0.16682860752212622, 0.10242265419388719, 0.9996942905850926, 0.999778580008951, 0.9997215310103731, 0.9997898284577509, 0.9999205186239404, 0.9996490595313877, 0.9997683795009482, 0.999919270879074, 0.9996590755988863, 0.17666893056860225, 0.26225566478991247, 0.5609442081187417, 0.9998165309836962, 0.9998851139084697, 0.9996819930421021, 0.9999121561317624, 0.9996048316335429, 0.9998548357179252, 0.9997427478667787, 0.5374708521891541, 0.4624063576429052, 0.6848272754378739, 0.17146004932974604, 9.208380737365523e-05, 0.0012891733032311733, 0.142361566199671, 0.9998240197342788, 0.9999065208337854, 0.9999337209881773, 0.19363697246421002, 0.8063494013478877, 0.9995488765769851, 0.9996303403352713, 0.9999156796634817, 0.9998103223422431, 0.34851335956882623, 0.6513890282166359, 0.9999203332123324, 0.9999029107153016, 0.9999691248000211, 0.7458864914376354, 0.2540580154672797, 0.8332608450348878, 0.16646386147137646, 0.9997728389455734, 0.9998154803361886, 0.999794119861656, 0.9997420275091443, 0.999679005304749, 0.9996509168971853, 0.6445068409308333, 0.355359390739739, 0.9996052530841592, 0.9999095504579537, 0.3187360022181644, 0.681208105928894, 0.9999366024290596, 0.007414031660127749, 0.9923096058792035, 0.9996112340811032, 0.008587406943838293, 0.00037918420271493763, 0.47906578270067235, 0.0001561346717061508, 0.0006691485930263605, 0.0084758821783339, 0.10692994516561241, 0.0015167368108597505, 0.0029219488562151077, 0.3913180972018156, 0.9998874098312168, 0.9998402371769202, 0.9999710242420864, 0.00088361034311305, 0.0001338803550171288, 0.2812290737489807, 5.3552142006851514e-05, 0.00021420856802740606, 0.024259120329103736, 0.00016065642602055454, 0.0001338803550171288, 0.6929379414976552, 0.9999183053911822, 0.9998331339612172, 0.23899809027771401, 0.7608196609637935, 0.9999211471838266, 0.9997923425131956, 0.9997811178766499, 0.9998224725874789, 0.9997787419967868, 0.9998636575054299, 0.3072897229592894, 0.6926392374848594, 0.9998920088809148, 0.8064506190576486, 0.19343647390848645, 5.697687007613739e-05, 0.9998486691800685, 0.9998054803097389, 0.9996720316747303, 0.9996094110592451, 0.9999754244483384, 0.41325601668907985, 0.5866415850797988, 0.013849329037294876, 0.986038031581229, 0.9997958525981896, 0.9998607894873957, 0.9996433418640914, 0.9997451691465113, 0.999625913957969, 0.9999757922721084, 0.9998745746865784, 0.999719406105342, 0.999741222317984, 0.9998539696167472, 0.9999628105616571, 0.9998823011889661, 0.9997106287653734, 0.21079007628553473, 0.43836513738545685, 0.11154681655774916, 0.020533088219541844, 0.11684304963025002, 0.10176915550082447, 0.00016296101761541148, 0.9997349101733524, 0.3043030658391527, 0.6956120118324591, 0.9999195570982168, 0.9998844495156899, 0.9998651854692522, 0.9998396686576625, 0.9998791803670751, 0.9998404361402474, 0.9998695848315791, 0.9997018218849838, 0.9997672926386738, 0.9997510033288104, 0.9997568748121141, 0.9998321949807711, 0.999551581885313, 0.9997499502856872, 0.9997011016278554, 0.9998533437203552, 0.9998689359573866, 0.9999765769948712, 0.9996400766418457, 0.8877693564133395, 0.08952837282330413, 0.022757811796811123, 0.9997697194259397, 0.00016763409111769613, 0.9996248137124132, 0.9999287471420946, 0.6685357573400067, 0.33140461329154297, 0.9997761057341877, 0.9998676247938241, 0.9998341233370459, 0.08668354237414563, 0.1950200457052739, 0.3566285688742766, 0.08338540924824762, 0.12647623552356732, 0.15142732960644797, 0.00035849273107587114, 0.9997443035814813, 0.5870324624934499, 0.17451750223306342, 0.14906266847397914, 0.0004190096092030334, 0.08893478955334384, 0.00017408696159534933, 0.8136824584966628, 0.18226904879033076, 0.0038299131550976855, 0.9998616627164274, 0.9998809562364243, 0.999738933706246, 0.9995437812396086, 0.9998359788574451, 0.9999184489479722, 0.9998022338972457, 0.9998971717051965, 0.9998328464941751, 0.9997583552689672, 0.9997859362961323, 0.9998174951715891, 0.9998867737155113, 0.00027898166227835567, 0.9995912959433484, 0.9998623504674115, 0.9998194262823871, 0.9998770711251326, 0.9995237602005487, 0.9999224233447966, 0.9996752977683329, 0.9996004450211092, 0.9998053691486737, 0.9996194125412444, 0.9998370707132139, 0.999649658960081, 0.9998545539439759, 0.9996472325368612, 0.9996760322183463, 0.999762774038434, 0.5641215199673054, 0.34105175321451947, 0.0946434732928005, 0.9997021636781903, 0.9996936348753273, 0.9998011290077181, 0.9997024565770292, 0.9998394534866176, 0.8162124467585068, 0.18362940078110682, 0.8213446803333689, 0.17843979427194917, 0.9998534816102128, 0.9998474623068323, 0.9999189919480683, 0.9999266509664265, 0.9996045913453484, 0.9998857115727792, 0.9998720013171878, 0.2833381939920757, 0.7163920946202396, 0.9998393341391769, 0.9995228628902073, 0.9999191394695058, 0.9998623562338577, 0.9998212822137741, 0.9998188154042403, 0.9997193377625487, 0.9997763973926793, 0.9997858521068737, 0.9997033711392528, 0.9998507280938249, 0.6750598146594584, 0.3248677029024112, 0.9998567132043561, 0.9996673557859139, 0.9996295903523241, 0.9996451767414094, 0.9998563067449527, 0.9996652425250251, 0.999746624999713, 0.9999435067340924, 0.9999001307674457, 0.9998459850477367, 0.9999222711793715, 0.9998980358912473, 0.999812049507265, 0.9994404471956844, 0.00028192960428651177, 0.9997732612446363, 0.9996855597447932, 0.8453959274034093, 0.1545697297358209, 0.9996988555373215, 0.9996286970687601, 0.999662443259165, 0.9996737861201287, 0.999640207067057, 0.9999246722566087, 0.9999285635286154, 0.9998431402034544, 0.9999082201916223, 0.9997446801475952, 0.9994981331551978, 0.9999071710731107, 0.9998694155447037, 0.9999049912938139, 0.9997187359201494, 0.9996011467365812, 0.9997158334294934, 0.999601901709796, 0.6474375191453045, 0.12427491923486682, 0.0013983531731000096, 0.2267712316035803, 5.950439034468126e-05, 0.99977004326822, 0.9996630436028812, 0.9996248651666318, 0.9999000015738654, 0.9999308860161163, 0.9998450310293547, 0.9995933681580478, 0.9995593458530962, 0.999486005921757, 0.9998342432628095, 0.9997327420192728, 0.7913368488952948, 0.20847860915524657, 0.9997170219266229, 0.9997788069332351, 0.06253593044466729, 0.910071498887811, 0.027272614110591016, 0.9999800800652842, 0.29394670441289056, 0.7058705123288465, 0.9997892362641208, 0.9997740737917794, 0.16787859799513202, 0.8321115086168351, 0.9995495961962418, 0.9997661439944994, 0.9998282479519847, 0.9998738343686377, 0.99961725969469, 0.9999008199984019, 0.9998236604850089, 0.9999368261526399, 0.9997788226507652, 0.9998999204417802, 0.9998081609072513, 0.9999384656780916, 0.9998511088336315, 0.14574906102102433, 0.8414979080015315, 0.012704518636215195, 0.9996199361548406, 0.9998756745717704, 0.9998479143173544, 0.9996906358945549, 0.9998542361259949, 0.9995832431974976, 0.9998581813154207, 0.2651176778574132, 0.09875135634035517, 0.0422949151035196, 0.00025288439523778536, 0.1720562204099082, 0.05762603156481033, 0.16854744942598393, 0.06461196298325415, 0.13067801123912556, 0.25227436021095273, 0.012839516402452842, 0.15469403555231115, 0.5800804962239212, 8.85483889824334e-05, 0.9996957476231757, 0.9998590725073424, 0.9999224379911279, 0.7382018233602398, 0.26176930036311885, 0.9997917016286297, 0.9997869702413165, 0.9997387137203783, 0.9998956488951029, 0.9998331881008246, 0.9997171011259384, 0.9995593717807576, 0.9998248944785609, 0.9998707260189624, 0.9998701328383826, 0.9994163573722117, 0.9998781107001319, 0.9997216454341786, 0.9999331876402424, 0.9998069984185355, 0.9996374691829957, 0.9997773310497169, 0.9996539985200674, 0.9996539385641908, 0.3270697635118147, 0.5185643797001629, 0.15424312711068536, 0.999906222452303, 0.9998761476751069, 0.9998740331292638, 0.9998603081011614, 0.9997951977540802, 0.9998978458462437, 0.9996813435198943, 0.9999548412859331, 0.9995717481255166, 0.9999086549911039, 0.9999288078149555, 0.9996749752039491, 0.9995829144190619, 0.9999627911618916, 0.9997964966955237, 0.9998587123253337, 0.9999123832623926, 0.9998469433402379, 0.999759655364411, 0.9997578268080224, 0.999681844020173, 0.9997187722711911, 0.9999090731615651, 0.9998217820741437, 0.91855940738004, 0.08139133989443392, 0.9997948277517964, 0.9999488125563963, 0.9996773813269223, 0.9997349287665886, 0.999838884477504, 0.9997280816618858, 0.999786744733845, 0.9998412475738492, 0.9999563161550462, 0.9998671311725429, 0.9999429028254128, 0.0037762856589053095, 0.9961133514631162, 0.9997531724146687, 0.9997618788650781, 0.9997456510780345, 0.38563669507647225, 0.6142205306864404, 0.9999241286052156, 0.9998864772299424, 0.9998171448044604, 0.9999008542410004, 0.9999320475328931, 0.9998811605836551, 0.9997098213502619, 0.4907273918659909, 0.5090331022401843, 0.8067603695614083, 0.19320037023875417, 0.999933993423671, 0.45838320558910295, 0.5415528961265685, 0.6265425202694419, 0.18080950477591246, 0.19259970880725205, 0.212591157525538, 0.49125381149066766, 0.18766140308189577, 0.1084877657588357, 0.9997558785080557, 0.9997933469348408, 0.9998772711205801], \"Term\": [\"aboriginal\", \"abuse\", \"accused\", \"action\", \"adelaide\", \"adelaide\", \"aged\", \"airport\", \"alan\", \"allegation\", \"alleged\", \"america\", \"amid\", \"amid\", \"andrew\", \"announces\", \"appeal\", \"arrest\", \"arrested\", \"assault\", \"attack\", \"attack\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australia\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"australian\", \"authority\", \"baby\", \"bank\", \"beach\", \"beat\", \"best\", \"biden\", \"black\", \"body\", \"border\", \"border\", \"border\", \"bos\", \"break\", \"briefing\", \"budget\", \"building\", \"bushfire\", \"bushfires\", \"business\", \"business\", \"call\", \"call\", \"call\", \"call\", \"call\", \"campaign\", \"canberra\", \"care\", \"case\", \"case\", \"cause\", \"central\", \"centre\", \"challenge\", \"change\", \"change\", \"charge\", \"charged\", \"child\", \"china\", \"china\", \"christmas\", \"christmas\", \"city\", \"claim\", \"climate\", \"close\", \"club\", \"coal\", \"coast\", \"coast\", \"come\", \"commission\", \"community\", \"community\", \"concern\", \"continue\", \"continue\", \"continues\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"coronavirus\", \"council\", \"country\", \"court\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"covid\", \"crash\", \"cricket\", \"crime\", \"crime\", \"crisis\", \"daniel\", \"darwin\", \"data\", \"david\", \"day\", \"dead\", \"dead\", \"deal\", \"death\", \"death\", \"death\", \"debate\", \"disability\", \"dollar\", \"domestic\", \"donald\", \"driver\", \"driver\", \"drug\", \"drug\", \"drum\", \"dy\", \"east\", \"economic\", \"economy\", \"election\", \"emergency\", \"energy\", \"expert\", \"extended\", \"face\", \"facebook\", \"fall\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"farm\", \"farmer\", \"farmer\", \"fatal\", \"federal\", \"festival\", \"final\", \"finance\", \"find\", \"flight\", \"food\", \"footage\", \"free\", \"friday\", \"funding\", \"george\", \"get\", \"girl\", \"global\", \"gold\", \"government\", \"great\", \"group\", \"group\", \"group\", \"guilty\", \"guilty\", \"head\", \"health\", \"high\", \"high\", \"hill\", \"history\", \"hold\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"home\", \"hong\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hospital\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"hour\", \"house\", \"housing\", \"human\", \"india\", \"indigenous\", \"indonesia\", \"industry\", \"inquest\", \"inside\", \"international\", \"interview\", \"investigation\", \"island\", \"island\", \"issue\", \"jail\", \"jailed\", \"james\", \"john\", \"johnson\", \"join\", \"kid\", \"kill\", \"killed\", \"killer\", \"killing\", \"kohler\", \"kong\", \"korea\", \"labor\", \"labor\", \"labor\", \"lake\", \"latest\", \"law\", \"lawyer\", \"lead\", \"leader\", \"leader\", \"league\", \"league\", \"leave\", \"left\", \"liberal\", \"life\", \"light\", \"live\", \"lockdown\", \"long\", \"long\", \"look\", \"make\", \"mark\", \"market\", \"mask\", \"medium\", \"meet\", \"mental\", \"michael\", \"military\", \"million\", \"minister\", \"minister\", \"missing\", \"monday\", \"money\", \"month\", \"morrison\", \"mother\", \"mount\", \"murder\", \"national\", \"near\", \"news\", \"north\", \"northern\", \"number\", \"number\", \"officer\", \"online\", \"open\", \"open\", \"opposition\", \"outback\", \"outbreak\", \"owner\", \"pacific\", \"pandemic\", \"park\", \"parliament\", \"party\", \"patient\", \"paul\", \"people\", \"peter\", \"plan\", \"plane\", \"play\", \"player\", \"point\", \"police\", \"police\", \"police\", \"police\", \"police\", \"politics\", \"positive\", \"post\", \"premier\", \"president\", \"price\", \"prime\", \"prince\", \"probe\", \"program\", \"project\", \"protest\", \"protest\", \"protester\", \"public\", \"quarantine\", \"quarantine\", \"quarantine\", \"queensland\", \"question\", \"question\", \"rape\", \"rate\", \"record\", \"record\", \"recovery\", \"refugee\", \"regional\", \"rescue\", \"research\", \"restriction\", \"result\", \"return\", \"review\", \"right\", \"rise\", \"risk\", \"river\", \"road\", \"road\", \"road\", \"robert\", \"rollout\", \"royal\", \"rugby\", \"rural\", \"russia\", \"russian\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"school\", \"school\", \"school\", \"school\", \"school\", \"scientist\", \"scott\", \"search\", \"season\", \"season\", \"second\", \"security\", \"sentenced\", \"service\", \"sexual\", \"share\", \"ship\", \"shooting\", \"shot\", \"show\", \"sign\", \"smith\", \"social\", \"south\", \"speaks\", \"sport\", \"spring\", \"star\", \"start\", \"state\", \"state\", \"state\", \"station\", \"stop\", \"storm\", \"story\", \"street\", \"student\", \"study\", \"sydney\", \"target\", \"tasmania\", \"tasmanian\", \"teen\", \"territory\", \"test\", \"testing\", \"thursday\", \"told\", \"tour\", \"tourism\", \"town\", \"trade\", \"train\", \"travel\", \"tree\", \"trial\", \"trial\", \"truck\", \"trump\", \"tuesday\", \"turn\", \"turnbull\", \"union\", \"university\", \"update\", \"vaccine\", \"victim\", \"victoria\", \"victorian\", \"victorian\", \"video\", \"violence\", \"wall\", \"warning\", \"warning\", \"water\", \"weather\", \"wednesday\", \"week\", \"west\", \"western\", \"white\", \"win\", \"win\", \"woman\", \"woman\", \"work\", \"worker\", \"worker\", \"world\", \"world\", \"world\", \"year\", \"year\", \"year\", \"year\", \"young\", \"youth\", \"zealand\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 10, 8, 5, 7, 3, 4, 9, 2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el96585126376898087428892649\", ldavis_el96585126376898087428892649_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el96585126376898087428892649\", ldavis_el96585126376898087428892649_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el96585126376898087428892649\", ldavis_el96585126376898087428892649_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "vis = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=bow_corpus, dictionary=dictionary)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363 : restriction : 0.023614423\n",
      "1287 : canberra : 0.02361012\n",
      "1465 : life : 0.022850947\n",
      "55 : water : 0.018874085\n",
      "237 : police : 0.01588662\n",
      "313 : missing : 0.015460977\n",
      "426 : country : 0.0153653445\n",
      "368 : concern : 0.014701052\n",
      "372 : claim : 0.014269243\n",
      "455 : farmer : 0.013329839\n",
      "2214 : officer : 0.012007995\n",
      "3361 : john : 0.011676877\n",
      "1737 : party : 0.011647861\n",
      "541 : search : 0.011593503\n",
      "293 : river : 0.010622957\n",
      "342 : western : 0.0103224795\n",
      "4403 : amid : 0.010024075\n",
      "396 : campaign : 0.009943682\n",
      "888 : crisis : 0.009788474\n",
      "277 : investigation : 0.009403193\n"
     ]
    }
   ],
   "source": [
    "#get the top 20 words and their weights for a specific topic\n",
    "topic_id=1\n",
    "top_terms=20\n",
    "for wordid, score in lda_model.get_topic_terms(topic_id, top_terms):\n",
    "    print(wordid, \":\", dictionary[wordid], \":\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Utility function to get the id for a word\n",
    "\n",
    "def get_id_for_word(dictionary, word):\n",
    "    for k, v in dictionary.iteritems():\n",
    "        if (v==word):\n",
    "            return k\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 7\n",
      "18888 : coronavirus : 0.035308406\n",
      "1363 : news : 0.019467585\n",
      "1300 : china : 0.017615708\n",
      "18889 : covid : 0.017266054\n",
      "37 : australia : 0.017129906\n",
      "26 : record : 0.016907472\n",
      "1188 : market : 0.015830228\n",
      "16 : australian : 0.015199825\n",
      "367 : live : 0.0132650295\n",
      "224 : coast : 0.011249922\n",
      "225 : gold : 0.010654345\n",
      "12 : rise : 0.010280104\n",
      "41 : million : 0.009715714\n",
      "852 : price : 0.009497092\n",
      "3204 : street : 0.009474546\n",
      "5235 : quarantine : 0.008613039\n",
      "567 : industry : 0.008337505\n",
      "110 : rate : 0.0076725883\n",
      "693 : high : 0.0074844514\n",
      "2262 : wall : 0.0071285265\n"
     ]
    }
   ],
   "source": [
    "top_terms=20\n",
    "index=get_id_for_word(dictionary,'market')\n",
    "for topic_id, score in lda_model.get_term_topics(index):\n",
    "    print(\"Topic:\", topic_id)\n",
    "    for wordid, score in lda_model.get_topic_terms(topic_id, top_terms):\n",
    "        print(wordid, \":\", dictionary[wordid], \":\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading your model for re-use\n",
    "\n",
    "Building a model takes time.Once you have a stable model, you can save it to disk and reload it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to disk.\n",
    "temp_file = \"./model\"\n",
    "lda_model.save(temp_file)\n",
    "\n",
    "# Load a potentially pretrained model from disk.\n",
    "loaded_lda = lda_model.load(temp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_document = 'How a Pentagon deal became an identity crisis for Google'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare any new text against the topic model, we first need to process it in the same way as we processed the input texts for the model.\n",
    "We apply the same preprocessing function and next apply the *doc2bow* function to represent it using the same vector representation as we used for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(888, 1), (1088, 1), (1921, 1), (5666, 1), (12406, 1)]\n"
     ]
    }
   ],
   "source": [
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "print(bow_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass this representation of the unseen document into the model to compare it against all the topics.\n",
    "The next function returns in index to the topics and a similarity score for the new document. We print the scores and the topics with the top 5 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.35016191005706787\t Topic_id 0\t Topic: 0.055*\"covid\" + 0.038*\"victoria\" + 0.037*\"coronavirus\" + 0.034*\"case\" + 0.023*\"child\"\n",
      "Score: 0.18343740701675415\t Topic_id 1\t Topic: 0.024*\"restriction\" + 0.024*\"canberra\" + 0.023*\"life\" + 0.019*\"water\" + 0.016*\"police\"\n",
      "Score: 0.18336418271064758\t Topic_id 7\t Topic: 0.035*\"coronavirus\" + 0.019*\"news\" + 0.018*\"china\" + 0.017*\"covid\" + 0.017*\"australia\"\n",
      "Score: 0.18297043442726135\t Topic_id 2\t Topic: 0.040*\"sydney\" + 0.030*\"election\" + 0.017*\"lockdown\" + 0.012*\"andrew\" + 0.011*\"state\"\n",
      "Score: 0.016677673906087875\t Topic_id 3\t Topic: 0.043*\"queensland\" + 0.026*\"south\" + 0.017*\"north\" + 0.016*\"victorian\" + 0.015*\"australia\"\n",
      "Score: 0.016677673906087875\t Topic_id 4\t Topic: 0.036*\"police\" + 0.030*\"woman\" + 0.027*\"court\" + 0.024*\"death\" + 0.023*\"donald\"\n",
      "Score: 0.016677673906087875\t Topic_id 5\t Topic: 0.030*\"government\" + 0.020*\"health\" + 0.015*\"tasmania\" + 0.014*\"plan\" + 0.013*\"federal\"\n",
      "Score: 0.016677673906087875\t Topic_id 6\t Topic: 0.021*\"crash\" + 0.017*\"house\" + 0.015*\"bushfire\" + 0.015*\"dy\" + 0.014*\"adelaide\"\n",
      "Score: 0.016677673906087875\t Topic_id 8\t Topic: 0.022*\"national\" + 0.017*\"change\" + 0.015*\"premier\" + 0.015*\"return\" + 0.014*\"tasmanian\"\n",
      "Score: 0.016677673906087875\t Topic_id 9\t Topic: 0.040*\"trump\" + 0.020*\"vaccine\" + 0.017*\"australia\" + 0.015*\"test\" + 0.014*\"open\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic_id {}\\t Topic: {}\".format(score, index, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This text matches best with topic 5 although the score is not very high!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the model with a new document\n",
    "\n",
    "We can also use the unseen documents to extend our model and update the topics. This is useful when processing texts in a stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/gensim/models/ldamodel.py:850: RuntimeWarning: overflow encountered in exp2\n",
      "  perwordbound, np.exp2(-perwordbound), len(chunk), corpus_words\n"
     ]
    }
   ],
   "source": [
    "# Update the model by incrementally training on the new corpus.\n",
    "\n",
    "other_texts = [['computer', 'time', 'graph'],['survey', 'response', 'eps'],['human', 'system', 'computer']]\n",
    "other_corpus = [dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "# Update the model by incrementally training on the new corpus.\n",
    "lda_model.update(other_corpus)  # update the LDA model with additional documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
